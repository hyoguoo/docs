---
layout: editorial
---

# Core Components

## 이벤트(Event)

카프카에서 다루는 데이터의 최소 단위를 의미하며, 이벤트는 단순히 데이터 덩어리가 아닌, 정형화된 구조를 가진다.(레코드 또는 메시지라고도 불림)

- 키(Key): 이벤트의 논리적인 식별자 역할을 하는 데이터
    - 키의 주된 목적은 파티셔닝과 로그 압축
    - 프로듀서가 기본 파티셔너를 사용할 경우, 동일한 키를 가진 이벤트들은 항상 동일한 파티션으로 전송되는 것을 보장
        - 특정 키에 대한 이벤트 처리 순서를 보장하는 핵심적인 메커니즘
    - 로그 압축(Log Compaction) 시에는 이 키를 기준으로 정렬하여, 동일 키의 최신 이벤트만 남기고 과거 이벤트를 정리하는 데 사용
- 값(Value): 이벤트의 실제 데이터 본문(Payload)
    - 보통 JSON, Avro, Protobuf 등 특정 포맷으로 직렬화된 바이트 배열 형태
    - 카프카 자체는 값의 내용을 해석하지 않으며, 단지 바이트 배열로 취급
- 타임스탬프(Timestamp): 이벤트에 연결된 시간 정보
    - 이벤트가 생성된 시간을 나타내는 `CreateTime`과, 카프카 브로커에 저장된 시간을 나타내는 `LogAppendTime` 두 가지 타입 존재
    - 타임스탬프로 시간 기반의 데이터 처리나 보관 정책(Retention)에 사용
- 헤더(Headers): 선택적인 메타데이터를 담는 공간
    - 이벤트의 값 자체를 변경하지 않으면서 추적 ID(Trace ID), 데이터 출처 정보 등 부가적인 컨텍스트를 전달하는 데 사용

## 토픽 내 구성 요소(Topic Components)

- 토픽(Topic): 이벤트 스트림을 구분하기 위한 논리적인 이름
    - 데이터베이스의 테이블이나 파일 시스템의 폴더와 유사한 개념
    - 프로듀서는 특정 토픽으로 이벤트를 발행하고 컨슈머는 특정 토픽의 이벤트를 구독
- 파티션(Partition): 하나의 토픽을 구성하는 물리적인 데이터 저장소
    - 토픽은 하나 이상의 파티션으로 구성되며, 각 파티션은 순서가 보장되는 불변의 로그(Immutable Log)
    - 이 파티션을 통해 카프카의 병렬처리와 확장성 구현
        - 한 토픽의 처리량을 늘리려면 파티션 수를 늘리는 방식으로 수평 확장 가능
        - 단, 이벤트 처리 순서는 토픽 전체가 아닌 파티션 내에서만 보장(병렬처리를 위해 글로벌 순서 보장을 포기한 중요한 아키텍처적 트레이드 오프)
- 오프셋(Offset): 파티션 내에서 각 이벤트가 가지는 유일하고 순차적인 식별 번호
    - `long` 타입의 정수 값이며, 해당 파티션 내에서는 절대 중복되거나 재사용되지 않고 단조 증가(Monotonically Increasing)
    - 컨슈머는 이 오프셋을 기준으로 자신이 어디까지 이벤트를 처리했는지 위치를 기록

## 브로커 & 클러스터(Broker & Cluster)

- 브로커(Broker): 카프카 서버 한 대를 의미하는 단위
    - 브로커는 파티션 로그의 물리적 저장, 데이터의 복제, 그리고 클라이언트의 읽기/쓰기 요청 처리를 담당
- 클러스터 (Cluster): 여러 대의 브로커가 함께 동작하는 그룹
    - 클러스터 구성을 통해 단일 브로커의 장애에 대응하는 고가용성을 확보하고, 부하를 여러 브로커에 분산하여 전체 시스템의 처리 용량을 수평적으로 확장
    - 클러스터 내 브로커 중 한 대는 컨트롤러(Controller) 역할을 수행하며, 파티션의 리더 선출이나 브로커의 상태 변화 감지 등 클러스터 전체의 메타데이터를 관리

## 프로듀서 & 파티셔너(Producer & Partitioner)

프로듀서는 이벤트를 생성하여 카프카 토픽으로 전송하는 클라이언트 애플리케이션을 의미하며, 이벤트를 보낼 토픽과 파티션을 결정하는 주체를 파티셔너(Partitioner)라고 한다.

### 메시지 전송 전략

프로듀서가 이벤트를 어떤 파티션으로 보낼지 결정하는 전략은 메시지 키(Key)의 존재 여부에 따라 구분된다.

- 키가 있는 경우 해시값을 기반으로 파티션을 선택하여 순서를 보장
- 키가 없는 경우 라운드로빈(Round Robin) 또는 스티키(Sticky) 파티셔너를 사용하여 부하 분산 및 처리량 극대화

```
                                { TopicA [ P0 | P1 | P2 ] }
Producer ---> Partitioner --->  { TopicB [ P0 | P1 | P2 ] }
                                { TopicC [ P0 | P1 | P2 ] }
```

#### 키가 있는 경우: 순서 보장

메시지에 특정 키를 할당하면, 프로듀서는 키의 해시값(Hash Value)을 계산하여 데이터를 보낼 파티션을 일관되게 결정한다.

- 동작 원리: 동일한 키를 가진 메시지들은 항상 같은 해시 값을 가지므로, 반드시 동일한 파티션으로 전송
- 주요 목적: 특정 식별자(예: 사용자 ID, 주문 번호)를 기준으로 데이터의 처리 순서를 보장해야 할 때 사용

#### 키가 없는 경우: 처리량 극대화

메시지에 키가 없으면, 프로듀서는 순서를 보장할 필요가 없다고 판단하고 처리량을 극대화하는 방향으로 동작한다.

- 과거 방식 (Round-Robin): 메시지를 파티션별로 하나씩 순차 분배
    - 부하는 균등해지지만, 각 파티션으로 보내는 배치가 작게 형성되어 네트워크 오버헤드가 증가하고 전체 처리량이 저하될 수 있음
- 최신 방식 (Sticky Partitioner): 하나의 파티션에 메시지를 집중적으로 보내 배치를 최대화
    - 이 방식은 메시지를 최대한 큰 배치(Batch)로 묶어 전송하므로 네트워크 오버헤드를 최소화하고 전체 처리량을 극대화합니다.
    - 동작 방식
        1. 하나의 파티션을 임의로 선택
        2. 배치 버퍼가 가득 차거나 `linger.ms` 시간이 초과될 때까지 해당 파티션에만 메시지를 계속 전송
        3. 배치가 전송되면, 다음 파티션을 선택하여 위 과정을 반복

### 메시지 전송 신뢰성 설정

프로듀서가 메시지를 브로커에 전송할 때, 데이터 손실 없이 안정적으로 전달되도록 하기 위해 다양한 신뢰성 설정을 제공한다.

- `acks` 옵션: 프로듀서가 메시지를 전송할 때 브로커로부터 어떤 수준의 응답을 기다릴지 결정

| acks 모드  |        동작         |        장점         |        단점         |
|:--------:|:-----------------:|:-----------------:|:-----------------:|
|  acks=0  |  브로커 응답 없이 성공 처리  |     빠른 전송 속도      |   데이터 손실 가능성 높음   |
|  acks=1  |  리더가 메시지 수신 시 성공  |  적절한 성능과 신뢰성 균형   | 리더 장애 시 데이터 손실 가능 |
| acks=all | 모든 ISR 복제 완료 시 성공 | 강력한 내구성 및 데이터 무결성 | 처리 지연 및 성능 저하 가능  |

- `enable.idempotence=true` : 동일 메시지를 여러 번 전송하더라도 단 한 번만 기록되도록 보장 (네트워크 오류나 재시도 시에도 중복 방지)

### 압축과 배치

프로듀서는 네트워크 효율성과 브로커 부하를 줄이기 위해 메시지를 압축하고 배치 단위로 묶어 전송하는 방식을 사용한다.

- 압축(Compression): 여러 메시지를 하나의 압축된 블록으로 묶어 전송하여 네트워크 대역폭 절약
    - 지원하는 압축 알고리즘: GZIP, Snappy, LZ4, ZSTD 등
    - 압축은 프로듀서 설정에서 `compression.type` 옵션으로 지정 가능
    - 네트워크 오버헤드를 줄여 처리량을 높이는 데 효과적이지만, 압축/해제 과정에서 Producer / Consumer CPU 사용량이 증가할 수 있음
- 배치(Batching): 여러 메시지를 하나의 배치로 묶어 한 번에 전송
    - 배치 크기(`batch.size`)와 대기 시간(`linger.ms`) 설정을 통해 조절 가능
    - 배치 크기가 크거나 대기 시간이 길어질수록 처리량은 증가하지만, 지연 시간도 함께 증가할 수 있음

## 컨슈머와 컨슈머 그룹(Consumer & Consumer Group)

컨슈머는 카프카 토픽에서 이벤트를 읽어가는 클라이언트 애플리케이션을 의미하며, 컨슈머 그룹은 동일한 목적을 위해 특정 토픽을 구독하는 컨슈머들의 집합이다.

- 컨슈머(Consumer): 토픽에서 이벤트를 가져와서(Pull) 처리하는 클라이언트 애플리케이션
    - 각 컨슈머는 자신이 읽은 이벤트의 오프셋(Offset)을 관리하며, 필요에 따라 오프셋을 커밋하여 어디까지 읽었는지 기록
    - 오프셋 커밋 방식에는 자동 커밋(auto-commit)과 수동 커밋(manual commit)이 있으며, 일반적으로 처리 완료 후 배치 단위로 커밋하는 방식을 권장
- 컨슈머 그룹(Consumer Group): 동일한 목적을 위해 특정 토픽을 구독하는 컨슈머들의 집합
    - 카프카 컨슈머의 확장성과 고가용성을 구현하는 핵심 개념
    - 토픽의 각 파티션은 컨슈머 그룹 내 단 하나의 컨슈머에게만 할당
        - 예시
            - 10개의 파티션을 가진 토픽이 있다면, 한 컨슈머 그룹은 최대 10개의 컨슈머를 투입하여 병렬로 데이터를 처리 가능
                - 더 추가하더라도 파티션 수가 부족하여 추가 컨슈머는 유휴 상태
            - 만약 그룹 내 컨슈머 중 하나에 장애가 발생하면, 카프카는 리밸런스(Rebalance) 과정을 통해 다른 컨슈머에게 자동으로 재할당
    - 각 그룹이 독립적인 오프셋 관리
        - 동일한 토픽을 여러 컨슈머 그룹이 각자 독립적으로 구독 가능(동일한 이벤트를 서로 다른 목적으로 처리 가능)

### 메시지 수신 전략

컨슈머는 브로커로부터 메시지를 수신하기 위해 정해진 전략에 따라 동작하며, 이는 시스템의 부하 관리와 지연/처리량 특성에 직접적인 영향을 준다.

- 풀(Pull) 모델 기반 동작
    - 카프카 컨슈머는 브로커가 밀어주는 푸시(Push) 방식이 아니라, 컨슈머가 `poll()`로 직접 가져오는 Pull 방식을 사용
    - 컨슈머가 처리 가능한 만큼만 데이터를 가져와 Flow Control이 용이
    - 지연/처리량 튜닝 파라미터
        - `fetch.min.bytes`(최소 바이트 충족 시 응답)
        - `fetch.max.wait.ms`(최대 대기시간)
        - `max.partition.fetch.bytes`(파티션별 최대 페치 크기)
        - `max.poll.records`(`poll()` 1회당 최대 레코드 수)
- 파티션 할당 전략(Partition Assignment Strategy)
    - 각 컨슈머 그룹 내에서 파티션을 컨슈머에게 할당하는 방식을 결정 가능
    - 지원하는 할당 전략
        - Range: 각 컨슈머에 연속된 파티션 범위를 할당(편향 가능)
        - RoundRobin: 파티션을 라운드로빈으로 분배(상대적으로 균등)
        - Sticky / CooperativeSticky: 기존 할당을 최대한 유지해 리밸런스 비용 최소화(운영 권장)
- 컨슈머 리밸런싱(Consumer Rebalancing)
    - 확장성과 고가용성을 위해 컨슈머 그룹 내에서 파티션 할당이 동적으로 변경되는 과정
    - 트리거: 컨슈머 조인/이탈, 토픽 파티션 수 변경 등
    - `session.timeout.ms`, `heartbeat.interval.ms` 등의 설정을 통해 리밸런스 감지 민감도 조절 가능

### 트랜잭션 메시지 격리 수준

컨슈머가 메시지를 읽을 때, 트랜잭션 메시지의 노출 여부를 제어하는 격리 수준(Isolation Level)을 설정할 수 있다.

- read_uncommitted: 트랜잭션 상태와 무관하게 기록 순서대로 모두 읽음
- read_committed: 커밋된 트랜잭션의 메시지만 노출

### 메시지 커밋 전략

컨슈머가 메시지를 어디까지 처리했는지에 대한 오프셋(Offset)을 기록하는 행위를 커밋(Commit)이라고 하며, 이 커밋 전략에 따라 메시지 처리의 신뢰성 수준이 결정된다.

- 자동 커밋(Auto Commit)
    - `enable.auto.commit=true`로 설정
    - 컨슈머에서 `auto.commit.interval.ms` 주기로 가장 마지막 오프셋을 자동으로 커밋
    - `poll()`로 가져온 데이터의 처리가 완료되기 전에 자동 커밋 발생 가능
        - 중복 문제: 메시지 처리는 완료했지만 커밋 전에 장애가 발생하면, 컨슈머는 마지막 커밋된 오프셋부터 다시 읽어 중복 처리 발생
        - 유실 문제: 메시지 처리가 완료되지 않았는데 커밋이 발생하면, 장애 시 해당 메시지를 다시 읽지 않고 유실될 수 있음
- 수동 커밋(Manual Commit)
    - `enable.auto.commit=false`로 설정
    - 개발자가 코드 내에서 명시적으로 커밋 시점을 제어하는 방식
    - 일반적으로는 동기 커밋을 주로 사용하고, 애플리케이션 종료 직전이나 처리량 확보가 매우 중요한 특정 구간에서 비동기 커밋을 보조적으로 활용
    - 동기 커밋 (Sync Commit)
        - 브로커로부터 커밋이 성공적으로 완료되었다는 응답을 받을 때까지 블로킹(Blocking)
        - 응답을 기다리는 동안 메시지 처리가 일시 중단되지만, 커밋 실패 시 예외를 통해 명확하게 인지하고 재시도할 수 있어 신뢰성이 높음
    - 비동기 커밋 (Async Commit)
        - 커밋 요청을 보낸 후 응답을 기다리지 않고 즉시 다음 작업으로 넘어감
        - 블로킹이 없어 처리량은 높지만, 커밋 실패 시 재시도가 어렵다는 단점이 있습니다.
    - 루프에선 commitAsync() -> 종료/리밸런스 직전엔 commitSync() 방식으로 혼합 사용 권장

### 메시지 처리 신뢰성 수준

컨슈머의 오프셋 커밋 전략과 트랜잭션 메시지 격리 수준, 그리고 애플리케이션의 메시지 처리 방식을 조합하여 다양한 신뢰성 수준을 구현할 수 있다.

- 최소 한 번 처리(At-Least-Once)
    - 메시지를 모두 처리한 후에 수동으로 오프셋을 커밋하는 방식으로 구현
    - 만약 처리는 완료했지만 커밋하기 전에 장애가 발생하면, 컨슈머는 마지막으로 커밋된 오프셋부터 다시 메시지를 가져와 재처리
        - 메시지 중복 처리가 발생할 수 있으므로, 컨슈머 애플리케이션은 멱등성(Idempotence)을 고려한 설계 필요
- 정확히 한 번 처리 (Exactly-Once)
    - 메시지의 유실이나 중복 없이 정확히 한 번만 처리하는 것을 보장하는 방식
    - 컨슈머는 `isolation.level=read_committed`로 설정하여 트랜잭션이 완료된 메시지만 수신
    - 메시지 처리와 오프셋 커밋을 하나의 원자적인 트랜잭션으로 묶어서 처리
