---
layout: editorial
---

# Core Components

## 이벤트(Event)

카프카에서 다루는 데이터의 최소 단위를 의미하며, 이벤트는 단순히 데이터 덩어리가 아닌, 정형화된 구조를 가진다.(레코드 또는 메시지라고도 불림)

- 키(Key): 이벤트의 논리적인 식별자 역할을 하는 데이터
    - 키의 주된 목적은 파티셔닝과 로그 압축
    - 프로듀서가 기본 파티셔너를 사용할 경우, 동일한 키를 가진 이벤트들은 항상 동일한 파티션으로 전송되는 것을 보장
        - 특정 키에 대한 이벤트 처리 순서를 보장하는 핵심적인 메커니즘
    - 로그 압축(Log Compaction) 시에는 이 키를 기준으로 정렬하여, 동일 키의 최신 이벤트만 남기고 과거 이벤트를 정리하는 데 사용
- 값(Value): 이벤트의 실제 데이터 본문(Payload)
    - 보통 JSON, Avro, Protobuf 등 특정 포맷으로 직렬화된 바이트 배열 형태
    - 카프카 자체는 값의 내용을 해석하지 않으며, 단지 바이트 배열로 취급
- 타임스탬프(Timestamp): 이벤트에 연결된 시간 정보
    - 이벤트가 생성된 시간을 나타내는 `CreateTime`과, 카프카 브로커에 저장된 시간을 나타내는 `LogAppendTime` 두 가지 타입 존재
    - 타임스탬프로 시간 기반의 데이터 처리나 보관 정책(Retention)에 사용
- 헤더(Headers): 선택적인 메타데이터를 담는 공간
    - 이벤트의 값 자체를 변경하지 않으면서 추적 ID(Trace ID), 데이터 출처 정보 등 부가적인 컨텍스트를 전달하는 데 사용

## 토픽 내 구성 요소(Topic Components)

- 토픽(Topic): 이벤트 스트림을 구분하기 위한 논리적인 이름
    - 데이터베이스의 테이블이나 파일 시스템의 폴더와 유사한 개념
    - 프로듀서는 특정 토픽으로 이벤트를 발행하고 컨슈머는 특정 토픽의 이벤트를 구독
- 파티션(Partition): 하나의 토픽을 구성하는 물리적인 데이터 저장소
    - 토픽은 하나 이상의 파티션으로 구성되며, 각 파티션은 순서가 보장되는 불변의 로그(Immutable Log)
    - 이 파티션을 통해 카프카의 병렬처리와 확장성 구현
        - 한 토픽의 처리량을 늘리려면 파티션 수를 늘리는 방식으로 수평 확장 가능
        - 단, 이벤트 처리 순서는 토픽 전체가 아닌 파티션 내에서만 보장(병렬처리를 위해 글로벌 순서 보장을 포기한 중요한 아키텍처적 트레이드 오프)
- 오프셋(Offset): 파티션 내에서 각 이벤트가 가지는 유일하고 순차적인 식별 번호
    - `long` 타입의 정수 값이며, 해당 파티션 내에서는 절대 중복되거나 재사용되지 않고 단조 증가(Monotonically Increasing)
    - 컨슈머는 이 오프셋을 기준으로 자신이 어디까지 이벤트를 처리했는지 위치를 기록

## 브로커 & 클러스터(Broker & Cluster)

- 브로커(Broker): 카프카 서버 한 대를 의미하는 단위
    - 브로커는 파티션 로그의 물리적 저장, 데이터의 복제, 그리고 클라이언트의 읽기/쓰기 요청 처리를 담당
- 클러스터 (Cluster): 여러 대의 브로커가 함께 동작하는 그룹
    - 클러스터 구성을 통해 단일 브로커의 장애에 대응하는 고가용성을 확보하고, 부하를 여러 브로커에 분산하여 전체 시스템의 처리 용량을 수평적으로 확장
    - 클러스터 내 브로커 중 한 대는 컨트롤러(Controller) 역할을 수행하며, 파티션의 리더 선출이나 브로커의 상태 변화 감지 등 클러스터 전체의 메타데이터를 관리

## 프로듀서 & 파티셔너(Producer & Partitioner)

프로듀서는 이벤트를 생성하여 카프카 토픽으로 전송하는 클라이언트 애플리케이션으로, 이때 파티셔너는 프로듀서가 보낼 이벤트가 토픽의 어느 파티션으로 가야 할지를 결정한다.

- 파티셔닝: 이벤트에 포함된 키(Key) 유무에 따라 특정 파티션에 순서를 보장하거나, 여러 파티션에 작업을 분산
- 전송 보장: `acks` 설정을 통해 데이터 전송 보장 수준을 조절하며, 재시도(`retries`) 메커니즘을 통해 일시적인 오류에 대응
- 고성능 처리: 내부적으로 이벤트를 배치(Batch)로 묶고 압축하여 네트워크 효율성을 극대화
- 중복 방지: 멱등성(Idempotence) 옵션을 통해 재시도 시 발생할 수 있는 메시지 중복 전송을 방지 가능

## 컨슈머와 컨슈머 그룹(Consumer & Consumer Group)

컨슈머는 카프카 토픽에서 이벤트를 읽어가는 클라이언트 애플리케이션이며, 컨슈머 그룹은 동일한 목적을 위해 특정 토픽을 구독하는 컨슈머들의 집합이다.

- 병렬 처리: 하나의 토픽을 여러 컨슈머가 병렬로 처리하여 높은 처리량을 달성하는 확장성의 핵심 단위
- 파티션 소유권: 토픽의 각 파티션은 그룹 내 단 하나의 컨슈머에게만 할당되어, 데이터 처리의 중복을 방지
- 고가용성: 그룹 내 컨슈머에 장애가 발생하면 리밸런싱(Rebalancing)을 통해 다른 컨슈머가 자동으로 해당 파티션을 인계받아 지속적인 데이터 처리를 보장
- 상태 관리: 컨슈머는 오프셋(Offset)을 커밋(Commit)하여 자신이 어디까지 이벤트를 처리했는지 위치를 기록하고 관리
