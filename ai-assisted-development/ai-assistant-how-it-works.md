---
layout: editorial
---

# AI 어시스턴트의 작동 원리

과거의 도구는 정해진 규칙(linting 등)으로 코드를 검사했으나, 반면 현대의 AI 어시스턴트는 대형 언어 모델(LLM)을 기반으로 한다.

- 기능 구현: 자연어 명령을 실제 코드로 변환
- 디버깅: 버그 리포트를 분석하고, 문제의 원인을 찾아 수정 방안 제시
- 테스트 작성: 기존 코드를 분석하여 테스트 케이스 자동 생성
- 워크플로우 수행: 깃 메시지 작성, 코드 리뷰, 문서화 등 개발 수명 주기 전반

AI 어시스턴트는 단순 자동 완성 도구가 아닌, 개발자의 생산성을 획기적으로 향상시키는 강력한 도구이다.

## 컨텍스트(Context)

컨텍스트(Context)란 AI가 현재 작업을 수행하기 위해 알아야 하는 모든 '정보'를 의미한다.

1. 대화 내역: 이전 대화에서 주고받은 메시지
2. 참조된 코드/파일: 사용자가 명시적으로 지정한 소스 코드
3. 프로젝트 구조: AI가 파악한 프로젝트의 전체 폴더 및 파일 목록
4. 시스템 프롬프트: AI의 역할이나 규칙을 미리 지정해 둔 기본 설정값

### 컨텍스트 구성 방식

사용자가 입력하는 메시지만이 컨텍스트의 전부가 아닌, AI가 실제로 작업을 처리할 때 여러 요소가 조합되어 채워진다.

- 시스템 프롬프트
    - 컨텍스트 윈도우의 맨 처음에 위치
    - AI의 정체성, 역할, 기본 규칙을 정의
    - 사용자가 직접 수정하기 전까지 모든 대화에 기본적으로 적용
- 참조된 코드/파일
    - 사용자가 파일을 참조하거나, AI가 프로젝트 구조를 분석할 때 발생
    - AI는 전체 프로젝트를 통째로 컨텍스트에 넣는 것이 불가능하므로, 관련성 높은 코드 조각들만 선별하여 추가
- 대화 내역
    - 이전 대화들이 순서대로 컨텍스트에 포함
- 사용자 입력
    - 사용자가 마지막에 입력한 새로운 질문이나 명령이 컨텍스트의 맨 끝에 추가

이 모든 요소가 합쳐져 하나의 거대한 프롬프트(명령문)를 구성하고, AI 모델은 이를 바탕으로 응답을 생성한다.

## Context Window의 한계와 토큰

AI의 응답 품질이 갑자기 떨어지거나 의도를 파악 못한다면, 대부분 '컨텍스트 용량 초과' 문제 때문이다.

- 토큰(Token): AI가 정보를 처리하는 기본 단위
- Context Window: AI가 한 번에 기억할 수 있는 토큰의 최대 개수
- 한계: 이 용량을 넘어서는 정보(긴 대화, 많은 참조 파일)가 입력되면, AI는 가장 오래된 정보부터 잊어버리기 시작

따라서 AI 성능을 높이려면, 한정된 컨텍스트 윈도우 안에 지금 작업에 꼭 필요한 정보만 정확하게 넣어주는 관리(prompt engineering)가 필수적이다.

### 토큰(Token)의 작동 방식과 비용

토큰은 단순히 단어가 아닌, AI가 세상을 이해하는 어휘(Vocabulary) 집합에 가깝다.

- 토큰화(Tokenization)
    - 모델은 학습 데이터에서 통계적으로 자주 등장하는 문자열을 하나의 토큰으로 인식
    - 예를 들어 `function`이나 `import`처럼 자주 쓰이는 단어는 1개의 토큰으로 처리
    - 하지만 `MyCustomVariable` 같은 드문 단어는 `My`, `Custom`, `Variable`처럼 3개 이상의 토큰으로 분리될 수 있음
- 언어별 효율 차이
    - 대부분의 모델은 영어 데이터 위주로 학습
    - 따라서 영어는 1단어 = 1토큰에 가까워 효율이 높음
    - 한국어는 구조가 달라 한 글자나 조사가 별도 토큰으로 분리되는 경우가 많음(예: '안녕하세요' -> '안녕', '하세', '요' 3~4 토큰)
    - 동일한 의미의 질문도 한국어로 하면 영어보다 더 많은 토큰이 소모될 수 있음
- 비용과 직결되는 문제
    - 대부분의 AI 서비스는 사용한 토큰의 총량에 따라 비용을 청구
    - `입력 토큰 수(컨텍스트) + 출력 토큰 수(AI 응답)` = 총비용
    - 컨텍스트 윈도우가 크다는 것 -> 한 번에 더 많은 토큰을 처리할 수 있다는 의미
    - 거대한 파일을 통째로 첨부하거나, 불필요하게 긴 대화를 이어가는 것은 AI의 성능 저하뿐만 아니라 직접적인 비용 증가로 이어짐

## RAG

AI가 수백 개의 파일로 이루어진 프로젝트를 다루기 위해 RAG(Retrieval-Augmented Generation)라는 기술을 사용한다.

1. 색인화(Indexing)
    - 코드를 작은 조각(chunk)으로 나누고, 각 조각의 '의미'를 나타내는 수학적 좌표(Vector Embedding)를 계산하여 데이터베이스에 저장
    - 예: `UserService.java` 파일의 `login()` 메서드 코드를 하나의 조각으로 나누고, 해당 코드의 벡터를 생성하여 색인에 추가
2. 검색(Retrieval)
    - 사용자가 "로그인 관련 버그 수정해줘"라고 질문하면, AI는 이 질문의 의미(벡터)와 가장 가까운 코드 조각(벡터)을 색인에서 탐색
    - 이때 '로그인', '인증', 'User' 등의 키워드뿐만 아니라, 의미적으로 관련된 코드(e.g., `SecurityConfig`, `JwtProvider`)도 함께 탐색
3. 증강(Augmentation)
    - AI는 이렇게 찾아낸 3~5개의 가장 관련성 높은 코드 조각을 컨텍스트 창에 자동으로 삽입
    - 마지막으로 사용자 질문("...버그 수정해줘")과 함께 이 코드 조각들을 AI에 전달
4. 생성(Generation)
    - AI는 제공된 코드 조각과 질문을 바탕으로 응답을 생성

## 보안

프로덕션 코드에서 AI 어시스턴트 사용 시 가장 민감하고 중요한 부분으로, 내 코드가 반드시 AI 서버로 전송된다는 점을 이해하는 것이 중요하다.

- 무료/개인용 플랜: 모델 학습에 사용될 가능성이 높음
- 기업용(Enterprise) 유료 플랜: 일반적으로 데이터가 저장되거나 학습에 사용되지 않음(Zero-Retention) 보장 가능

따라서 민감한 코드를 다루기 전, 사용하려는 서비스의 데이터 프라이버시 및 이용 약관을 확인하는 것이 중요하다.
